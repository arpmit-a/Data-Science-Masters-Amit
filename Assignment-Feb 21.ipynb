{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66dd7952-040b-4256-ba0d-6386e8730e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q1\n",
    "Web scraping is an automated method of extracting data from websites. \n",
    "It is used for a variety of purposes such as data mining, price comparison, lead generation, monitoring consumer sentiment, news tracking, etc\n",
    "\n",
    "Here are three areas where web scraping is used to get data:\n",
    "Data mining: Web scraping tools can be used to extract large amounts of data from websites and then analyze it to uncover patterns, trends, and insights\n",
    "\n",
    "Price comparison: Web scraping can be used to gather data from multiple online retailers and compare prices on products\n",
    "\n",
    "Lead generation: Web scrapers can be used to extract contact information from websites such as LinkedIn or Facebook for sales leads\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7ba558f-4c5e-4273-bab0-6047ef1d99df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q2\n",
    "There are several methods used for web scraping, including:\n",
    "\n",
    "Manual Scraping: This involves manually copying and pasting data from a website into a local file or database. \n",
    "It is a time-consuming and labor-intensive method, but it is also the most basic and straightforward way of scraping data.\n",
    "\n",
    "DOM Parsing: This method involves parsing the Document Object Model (DOM) of a web page using an HTML parser to extract the data. \n",
    "The HTML parser navigates through the page's structure to locate specific HTML elements and extracts the data from them.\n",
    "\n",
    "Regular Expression: This method involves using regular expressions to match and extract specific patterns of data from the HTML code of a web page.\n",
    "Regular expressions are a powerful tool for extracting data, but they can be challenging to write and maintain.\n",
    "\n",
    "XPath: This method involves using XPath expressions to navigate and extract data from an XML or HTML document. \n",
    "XPath expressions can locate specific elements or attributes within a document and extract their values.\n",
    "\n",
    "Web Scraping Libraries: There are several web scraping libraries available in various programming languages, such as BeautifulSoup in Python, Scrapy, Puppeteer, and Selenium, that can automate the process of web scraping. \n",
    "These libraries provide tools for navigating web pages, extracting data, and storing it in a local file or database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c1f1b03-2aa4-4125-b26e-f44f77a84d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q3\n",
    "Beautiful Soup is a Python library that is commonly used for web scraping. \n",
    "It allows you to parse and extract data from HTML and XML documents.\n",
    "\n",
    "Web scraping is the process of collecting data from websites automatically. \n",
    "Beautiful Soup helps automate this process by providing a simple way to parse and navigate HTML and XML documents. It makes it easier to extract specific data points from a web page, such as article titles, product information, or customer reviews.\n",
    "\n",
    "Some of the key features of Beautiful Soup include:\n",
    "\n",
    "Parsing: Beautiful Soup can parse HTML and XML documents and create a parse tree that can be navigated and searched.\n",
    "\n",
    "Navigation: The library provides several methods to navigate the parse tree, allowing you to locate specific elements based on their attributes or their position in the document.\n",
    "\n",
    "Search: You can use Beautiful Soup to search for specific elements or patterns within the parse tree, such as all the links on a page or all the paragraphs that contain a certain keyword."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b38c3cf4-abec-438a-b3d6-f4ab7bb5f2c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q4\n",
    "In this project Flask is used as an IDE which provides a simple and lightweight way to create web servers and handle HTTP requests and responses.\n",
    "Web scraping involves sending HTTP requests to a web server and parsing the HTML response to extract data. \n",
    "Flask is used in web scraping to build a simple web application that acts as a user interface for the scraping comments,ratings etc. \n",
    "The user can enter a product name and Flask  passes the input to the scraping script and display the results in a user-friendly way.\n",
    "It renders the html pages.\n",
    "Flask is also  used to implement authentication and authorization mechanisms for web scraping, which is useful when accessing restricted content or when scraping large amounts of data over an extended period of time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e25738-ad1e-407a-a406-9923b69452ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q5\n",
    "The 2 services used in this project are :Code Pipeline,Beanstalk.\n",
    "\n",
    "#Pipeline\n",
    "CodePipeline is essentially used to automate the steps required to take code changes from a source code repository, such as GitHub, and move them through a series of stages that can include building, testing, and deployment. \n",
    "The pipeline is made up of several stages that each perform a specific set of actions.\n",
    "\n",
    "#Beanstalk\n",
    "With the help of code pipeline we push the code to beanstalk.Now beanstalk serves as a PaaS.\n",
    "Elastic Beanstalk simplifies the process of deploying and scaling web applications by handling the infrastructure, including the operating system, web server, and application server."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
